---
title: fioを使ったベンチマーク
date: 2015-02-09T22:27:00+09:00
slug: 2227
markup.goldmark.renderer.unsafe: true
categories:
  - blog
tags:
  - fio
  - benchmark
---


## Intro

ディスクベンチマークのツールとして、dbenchであるとか、もっと簡単にはhdparmなどがある。
今回はfioという、単純なread/writeの計測には必要十分なツールを使おうと思う。
ただ、ベンチマークツールはたいていオプションが多く、またアウトプットも複雑なので、一旦まとめてみる。

## オプション

### オプションの与え方
以下の2つが使える。

- コマンドラインオプションで与える
- オプションを記述したファイルを引数にする

        [global]
        rw=randread
        size=256m
        directory=/tmp/fio-test
        ioengine=libaio
        iodepth=4
        invalidate=1
        direct=1

        [random-read]
        rw=randread
        size=128m
        directory=/tmp/fio-test

        [random-write]
        rw=randwrite
        size=128m
        directory=/tmp/fio-test

### 主なオプション

| option | value | 意味 |
|-------|--------|-----|
| rw | read, write, randread, randwrite, randrw | ベンチマークの内容を決める。randrwはMixさせるもの。rwmixread=40でread 40%。|
| bs | <int\>[, <int\>] (default: 4k) | ブロックサイズ。2つ与えられていると、read, writeになる。 |
| size | <int\>, 64\{k,M, G, T, P\}, 10% など | Job全体のIOサイズ。単位はb。|
| numjobs | <int\> (default: 1) | 同じワークロードを実行するスレッドをいくつ生成するか。 |
| directory | <str\> | fioで使うファイルのプレフィックス。|
| name | <str\> | ジョブ名を上書きする |
| ioengine | sync, psync, vsync, libaio, ... | Job IOをどのように行うかを決める。 |
| iodepth | <int\> (default: 1) | ファイルに対するIO書き込みのユニット数。IO waitを作り出すのに使ったり、複数のヘッドがあるときに使われる? |
| direct | 0 or 1 (default: 0) | 1、つまりtrueの時、 non-buffered IOを使う。(たいていは O\_DIRECT) |
| invalidate | 0 or 1 (default: 1) | IO計測の前に、キャッシュを使わないようにしておく |
| runtime | <int\> | 実行最大時間 |
| thinktime | <int\> | IO発行の間で、Jobを止める。単位は microsecond(μs) |
| fsync | <int\> (default: 0) | IOが<int\>与えられるたびに、fsyncを呼ぶ。 0の時は呼ばない。 |
| write\_iolog | <str\> | IOパターンの書き出し。各Jobで異なるファイルを指定する必要がある。 |
| read\_iolog | <str\> | IOパターンの読み出し |

## アウトプットの見方
### 実行例

<pre>
# fio -filename=/mnt/test2g -direct=1 -rw=randwrite -bs=4k -size=2G -numjobs=64 -runtime=10 -group\_reporting -name=file1
file1: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=1
...
file1: (g=0): rw=randwrite, bs=4K-4K/4K-4K/4K-4K, ioengine=sync, iodepth=1
fio-2.1.3
Starting 64 processes
Jobs: 64 (f=29): [wwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwwww] [100.0% done] [0KB/315KB/0KB /s] [0/78/0 iops] [eta 00m:00s]
file1: (groupid=0, jobs=64): err= 0: pid=3845: Mon Feb  9 20:10:11 2015
  write: io=3256.0KB, bw=307748B/s, iops=75, runt= 10834msec
    clat (msec): min=7, max=10192, avg=205.55, stdev=1093.89
     lat (msec): min=7, max=10192, avg=205.55, stdev=1093.89
    clat percentiles (msec):
     |  1.00th=[    8],  5.00th=[    9], 10.00th=[   10], 20.00th=[   11],
     | 30.00th=[   12], 40.00th=[   13], 50.00th=[   13], 60.00th=[   14],
     | 70.00th=[   15], 80.00th=[   16], 90.00th=[   20], 95.00th=[  586],
     | 99.00th=[ 6849], 99.50th=[ 9110], 99.90th=[10159], 99.95th=[10159],
     | 99.99th=[10159]
    bw (KB  /s): min=    0, max=  332, per=18.29%, avg=54.86, stdev=114.66
    lat (msec) : 10=11.30%, 20=78.99%, 50=3.07%, 100=0.12%, 250=0.12%
    lat (msec) : 750=2.95%, 1000=0.37%, 2000=0.25%, >=2000=2.83%
  cpu          : usr=0.00%, sys=0.00%, ctx=1726, majf=0, minf=1909
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued    : total=r=0/w=814/d=0, short=r=0/w=0/d=0

Run status group 0 (all jobs):
  WRITE: io=3256KB, aggrb=300KB/s, minb=300KB/s, maxb=300KB/s, mint=10834msec, maxt=10834msec

Disk stats (read/write):
  sdc: ios=0/801, merge=0/2, ticks=0/10620, in\_queue=10624, util=98.48%
</pre>

### 実行結果の意味

| key | value |
|-----|-------|
| bw | バンド幅 |
| clat | completeion latency。リクエスト送信から終了までの遅延時間 |
| IO depths | 実行時のリクエスト待機状態。submit 以下の行は、IOリクエストまでに要したレイテンシ情報。この例では、0ms~4msですべて処理されている。 |
| WRITE | ここのスレッドにおける、帯域幅の平均など |

## 資料
- [man fio](http://linux.die.net/man/1/fio)
- [ファイルシステムのベンチマーク集](http://www.nminoru.jp/~nminoru/unix/fs_benchmarks.html)
- [fioを用いたディスクIOのパフォーマンス測定](http://sourceforge.jp/magazine/08/05/22/0127246)
- [Provisioned IOPSの検討 - JPOUG Advent Calendar 2012](http://d.hatena.ne.jp/sh2/20121217)
